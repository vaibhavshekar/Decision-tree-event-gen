{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - agent_accuracy: 0.3834 - anomaly_accuracy: 0.4564 - context_accuracy: 0.1087 - loss: 2.8103 - next_event_accuracy: 0.7103 - val_agent_accuracy: 0.5135 - val_anomaly_accuracy: 0.5338 - val_context_accuracy: 0.0878 - val_loss: 2.4440 - val_next_event_accuracy: 0.7973\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - agent_accuracy: 0.4082 - anomaly_accuracy: 0.5188 - context_accuracy: 0.0911 - loss: 2.4622 - next_event_accuracy: 0.8130 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.5608 - val_context_accuracy: 0.1216 - val_loss: 2.1994 - val_next_event_accuracy: 0.7973\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - agent_accuracy: 0.5120 - anomaly_accuracy: 0.4840 - context_accuracy: 0.1211 - loss: 2.1625 - next_event_accuracy: 0.8773 - val_agent_accuracy: 0.6351 - val_anomaly_accuracy: 0.5743 - val_context_accuracy: 0.1892 - val_loss: 1.8205 - val_next_event_accuracy: 0.9459\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - agent_accuracy: 0.6635 - anomaly_accuracy: 0.5086 - context_accuracy: 0.1680 - loss: 1.9204 - next_event_accuracy: 0.9247 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5473 - val_context_accuracy: 0.1959 - val_loss: 1.5854 - val_next_event_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - agent_accuracy: 0.7908 - anomaly_accuracy: 0.5220 - context_accuracy: 0.1726 - loss: 1.7285 - next_event_accuracy: 0.9619 - val_agent_accuracy: 0.9932 - val_anomaly_accuracy: 0.5608 - val_context_accuracy: 0.2297 - val_loss: 1.3740 - val_next_event_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - agent_accuracy: 0.9336 - anomaly_accuracy: 0.5200 - context_accuracy: 0.1797 - loss: 1.5498 - next_event_accuracy: 0.9797 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4527 - val_context_accuracy: 0.2770 - val_loss: 1.1930 - val_next_event_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - agent_accuracy: 0.9644 - anomaly_accuracy: 0.4863 - context_accuracy: 0.2238 - loss: 1.3959 - next_event_accuracy: 0.9858 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5068 - val_context_accuracy: 0.3446 - val_loss: 1.0794 - val_next_event_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - agent_accuracy: 0.9470 - anomaly_accuracy: 0.5506 - context_accuracy: 0.3075 - loss: 1.2215 - next_event_accuracy: 0.9864 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4459 - val_context_accuracy: 0.3514 - val_loss: 0.9082 - val_next_event_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - agent_accuracy: 0.9699 - anomaly_accuracy: 0.5008 - context_accuracy: 0.3285 - loss: 1.1578 - next_event_accuracy: 0.9898 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5068 - val_context_accuracy: 0.3446 - val_loss: 0.8737 - val_next_event_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - agent_accuracy: 0.9742 - anomaly_accuracy: 0.4886 - context_accuracy: 0.3768 - loss: 1.0753 - next_event_accuracy: 0.9945 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4730 - val_context_accuracy: 0.3581 - val_loss: 0.8323 - val_next_event_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 175ms/step - agent_accuracy: 0.9857 - anomaly_accuracy: 0.4640 - context_accuracy: 0.3781 - loss: 1.0326 - next_event_accuracy: 0.9914 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4459 - val_context_accuracy: 0.3986 - val_loss: 0.8044 - val_next_event_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - agent_accuracy: 0.9751 - anomaly_accuracy: 0.5192 - context_accuracy: 0.3329 - loss: 1.0651 - next_event_accuracy: 0.9859 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5068 - val_context_accuracy: 0.4324 - val_loss: 0.7970 - val_next_event_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 212ms/step - agent_accuracy: 0.9703 - anomaly_accuracy: 0.4987 - context_accuracy: 0.3989 - loss: 0.9876 - next_event_accuracy: 0.9820 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5000 - val_context_accuracy: 0.3919 - val_loss: 0.7762 - val_next_event_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - agent_accuracy: 0.9739 - anomaly_accuracy: 0.5387 - context_accuracy: 0.3802 - loss: 0.9667 - next_event_accuracy: 0.9956 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5135 - val_context_accuracy: 0.3919 - val_loss: 0.7714 - val_next_event_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 223ms/step - agent_accuracy: 0.9804 - anomaly_accuracy: 0.4848 - context_accuracy: 0.3714 - loss: 0.9416 - next_event_accuracy: 0.9972 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4595 - val_context_accuracy: 0.4324 - val_loss: 0.7566 - val_next_event_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - agent_accuracy: 0.9701 - anomaly_accuracy: 0.5482 - context_accuracy: 0.4105 - loss: 0.9135 - next_event_accuracy: 0.9928 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.4527 - val_loss: 0.7398 - val_next_event_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 182ms/step - agent_accuracy: 0.9850 - anomaly_accuracy: 0.5207 - context_accuracy: 0.4174 - loss: 0.9143 - next_event_accuracy: 0.9862 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5203 - val_context_accuracy: 0.4730 - val_loss: 0.7333 - val_next_event_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - agent_accuracy: 0.9895 - anomaly_accuracy: 0.5731 - context_accuracy: 0.4288 - loss: 0.8738 - next_event_accuracy: 0.9938 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4257 - val_context_accuracy: 0.4730 - val_loss: 0.7428 - val_next_event_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 198ms/step - agent_accuracy: 0.9833 - anomaly_accuracy: 0.5349 - context_accuracy: 0.4134 - loss: 0.8755 - next_event_accuracy: 0.9977 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.4392 - val_loss: 0.7336 - val_next_event_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - agent_accuracy: 0.9928 - anomaly_accuracy: 0.5011 - context_accuracy: 0.4305 - loss: 0.8777 - next_event_accuracy: 0.9962 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5135 - val_context_accuracy: 0.4527 - val_loss: 0.7197 - val_next_event_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - agent_accuracy: 0.9795 - anomaly_accuracy: 0.5287 - context_accuracy: 0.4188 - loss: 0.8826 - next_event_accuracy: 0.9932 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4730 - val_context_accuracy: 0.4595 - val_loss: 0.7183 - val_next_event_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - agent_accuracy: 0.9866 - anomaly_accuracy: 0.4741 - context_accuracy: 0.4319 - loss: 0.8457 - next_event_accuracy: 0.9962 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4459 - val_context_accuracy: 0.4797 - val_loss: 0.7308 - val_next_event_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - agent_accuracy: 0.9861 - anomaly_accuracy: 0.5387 - context_accuracy: 0.4282 - loss: 0.8478 - next_event_accuracy: 0.9976 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5068 - val_context_accuracy: 0.4730 - val_loss: 0.7125 - val_next_event_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - agent_accuracy: 0.9890 - anomaly_accuracy: 0.4935 - context_accuracy: 0.4260 - loss: 0.8332 - next_event_accuracy: 0.9935 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4662 - val_context_accuracy: 0.4662 - val_loss: 0.7209 - val_next_event_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - agent_accuracy: 0.9915 - anomaly_accuracy: 0.5205 - context_accuracy: 0.4308 - loss: 0.8278 - next_event_accuracy: 0.9967 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4595 - val_context_accuracy: 0.4865 - val_loss: 0.7204 - val_next_event_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - agent_accuracy: 0.9839 - anomaly_accuracy: 0.5277 - context_accuracy: 0.4422 - loss: 0.8022 - next_event_accuracy: 0.9979 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4527 - val_context_accuracy: 0.4662 - val_loss: 0.7249 - val_next_event_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - agent_accuracy: 0.9902 - anomaly_accuracy: 0.4748 - context_accuracy: 0.4543 - loss: 0.8121 - next_event_accuracy: 0.9972 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4662 - val_context_accuracy: 0.4730 - val_loss: 0.7094 - val_next_event_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 179ms/step - agent_accuracy: 0.9936 - anomaly_accuracy: 0.5418 - context_accuracy: 0.4406 - loss: 0.7894 - next_event_accuracy: 0.9960 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5000 - val_context_accuracy: 0.4595 - val_loss: 0.7150 - val_next_event_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - agent_accuracy: 0.9901 - anomaly_accuracy: 0.4854 - context_accuracy: 0.4445 - loss: 0.8127 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4797 - val_context_accuracy: 0.4662 - val_loss: 0.7217 - val_next_event_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - agent_accuracy: 0.9925 - anomaly_accuracy: 0.5634 - context_accuracy: 0.4620 - loss: 0.7894 - next_event_accuracy: 0.9996 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4797 - val_context_accuracy: 0.4730 - val_loss: 0.7261 - val_next_event_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - agent_accuracy: 0.9937 - anomaly_accuracy: 0.5092 - context_accuracy: 0.4508 - loss: 0.7964 - next_event_accuracy: 0.9979 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4189 - val_context_accuracy: 0.4932 - val_loss: 0.7219 - val_next_event_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - agent_accuracy: 0.9927 - anomaly_accuracy: 0.5202 - context_accuracy: 0.4776 - loss: 0.7821 - next_event_accuracy: 0.9970 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.4459 - val_loss: 0.7172 - val_next_event_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - agent_accuracy: 0.9879 - anomaly_accuracy: 0.5101 - context_accuracy: 0.4339 - loss: 0.8184 - next_event_accuracy: 0.9979 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5000 - val_context_accuracy: 0.4797 - val_loss: 0.7195 - val_next_event_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - agent_accuracy: 0.9858 - anomaly_accuracy: 0.4975 - context_accuracy: 0.4857 - loss: 0.7709 - next_event_accuracy: 0.9957 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5000 - val_context_accuracy: 0.4865 - val_loss: 0.7366 - val_next_event_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - agent_accuracy: 0.9964 - anomaly_accuracy: 0.4987 - context_accuracy: 0.4726 - loss: 0.7613 - next_event_accuracy: 0.9947 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5135 - val_context_accuracy: 0.4932 - val_loss: 0.7232 - val_next_event_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - agent_accuracy: 0.9928 - anomaly_accuracy: 0.4819 - context_accuracy: 0.4609 - loss: 0.7577 - next_event_accuracy: 0.9972 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5068 - val_context_accuracy: 0.4932 - val_loss: 0.7157 - val_next_event_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - agent_accuracy: 0.9845 - anomaly_accuracy: 0.5221 - context_accuracy: 0.4558 - loss: 0.7925 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.4459 - val_loss: 0.7246 - val_next_event_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - agent_accuracy: 0.9968 - anomaly_accuracy: 0.5097 - context_accuracy: 0.5078 - loss: 0.7386 - next_event_accuracy: 0.9943 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.4459 - val_loss: 0.7345 - val_next_event_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - agent_accuracy: 0.9933 - anomaly_accuracy: 0.5221 - context_accuracy: 0.4399 - loss: 0.7588 - next_event_accuracy: 0.9991 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4324 - val_context_accuracy: 0.4595 - val_loss: 0.7217 - val_next_event_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - agent_accuracy: 0.9893 - anomaly_accuracy: 0.5354 - context_accuracy: 0.4826 - loss: 0.7459 - next_event_accuracy: 0.9972 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4797 - val_context_accuracy: 0.4797 - val_loss: 0.7236 - val_next_event_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step - agent_accuracy: 0.9954 - anomaly_accuracy: 0.5315 - context_accuracy: 0.4826 - loss: 0.7397 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5338 - val_context_accuracy: 0.4662 - val_loss: 0.7271 - val_next_event_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - agent_accuracy: 0.9929 - anomaly_accuracy: 0.5620 - context_accuracy: 0.4461 - loss: 0.7672 - next_event_accuracy: 0.9979 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4730 - val_context_accuracy: 0.4662 - val_loss: 0.7281 - val_next_event_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - agent_accuracy: 0.9888 - anomaly_accuracy: 0.5356 - context_accuracy: 0.4931 - loss: 0.7654 - next_event_accuracy: 0.9967 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5203 - val_context_accuracy: 0.4730 - val_loss: 0.7364 - val_next_event_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - agent_accuracy: 0.9948 - anomaly_accuracy: 0.5332 - context_accuracy: 0.4952 - loss: 0.7299 - next_event_accuracy: 0.9966 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5338 - val_context_accuracy: 0.4932 - val_loss: 0.7442 - val_next_event_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - agent_accuracy: 0.9959 - anomaly_accuracy: 0.5103 - context_accuracy: 0.5003 - loss: 0.7129 - next_event_accuracy: 0.9989 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.4730 - val_loss: 0.7270 - val_next_event_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - agent_accuracy: 0.9942 - anomaly_accuracy: 0.5112 - context_accuracy: 0.5325 - loss: 0.7117 - next_event_accuracy: 0.9985 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5270 - val_context_accuracy: 0.4527 - val_loss: 0.7377 - val_next_event_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - agent_accuracy: 0.9919 - anomaly_accuracy: 0.5438 - context_accuracy: 0.5180 - loss: 0.7074 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5068 - val_context_accuracy: 0.4932 - val_loss: 0.7439 - val_next_event_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - agent_accuracy: 0.9914 - anomaly_accuracy: 0.5330 - context_accuracy: 0.5267 - loss: 0.6916 - next_event_accuracy: 0.9991 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4730 - val_context_accuracy: 0.4595 - val_loss: 0.7277 - val_next_event_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - agent_accuracy: 0.9897 - anomaly_accuracy: 0.4647 - context_accuracy: 0.5114 - loss: 0.7156 - next_event_accuracy: 0.9974 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4730 - val_context_accuracy: 0.4797 - val_loss: 0.7291 - val_next_event_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - agent_accuracy: 0.9896 - anomaly_accuracy: 0.5083 - context_accuracy: 0.4890 - loss: 0.7156 - next_event_accuracy: 0.9972 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.4662 - val_loss: 0.7318 - val_next_event_accuracy: 1.0000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.4732 - context_accuracy: 0.4448 - loss: 0.7156 - next_event_accuracy: 1.0000\n",
      "Test Loss and Accuracy: [0.7354834079742432, 1.0, 0.4899328947067261, 0.42281877994537354, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Dense, Concatenate, Conv1D, GlobalMaxPooling1D, MultiHeadAttention, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data Preprocessing\n",
    "def preprocess_data(df):\n",
    "    event_type_mapping = df['event_type'].astype('category').cat.categories\n",
    "    agent_id_mapping = df['agent_id'].astype('category').cat.categories\n",
    "    context_mapping = df['context'].astype('category').cat.categories\n",
    "\n",
    "    df['event_type'] = df['event_type'].astype('category').cat.codes\n",
    "    df['agent_id'] = df['agent_id'].astype('category').cat.codes\n",
    "    df['context'] = df['context'].astype('category').cat.codes\n",
    "\n",
    "    return df, event_type_mapping, agent_id_mapping, context_mapping\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('1k_single_agent_minmax.csv')\n",
    "df, event_type_mapping, agent_id_mapping, context_mapping = preprocess_data(df)\n",
    "\n",
    "# Define constants\n",
    "num_classes = df['event_type'].nunique()\n",
    "num_agents = df['agent_id'].nunique()\n",
    "num_contexts = df['context'].nunique()\n",
    "sequence_length = 10  # Adjust based on your data\n",
    "num_features = df.shape[1]  # Number of features\n",
    "\n",
    "# Create sequences for training\n",
    "def create_sequences(df, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(df) - sequence_length):\n",
    "        seq = df.iloc[i:i+sequence_length].values\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "sequences = create_sequences(df, sequence_length)\n",
    "\n",
    "# Splitting the data\n",
    "train_size = int(0.7 * len(sequences))\n",
    "val_size = int(0.15 * len(sequences))\n",
    "train_sequences = sequences[:train_size]\n",
    "val_sequences = sequences[train_size:train_size+val_size]\n",
    "test_sequences = sequences[train_size+val_size:]\n",
    "\n",
    "# Extract targets\n",
    "def extract_targets(sequences):\n",
    "    next_event = to_categorical(sequences[:, -1, 0], num_classes=num_classes)\n",
    "    agent = to_categorical(sequences[:, -1, 1], num_classes=num_agents)\n",
    "    context = to_categorical(sequences[:, -1, 2], num_classes=num_contexts)\n",
    "    anomaly = np.random.randint(0, 2, size=(sequences.shape[0], 1))  # Placeholder for anomaly\n",
    "    return next_event, agent, context, anomaly\n",
    "\n",
    "train_targets = extract_targets(train_sequences)\n",
    "val_targets = extract_targets(val_sequences)\n",
    "test_targets = extract_targets(test_sequences)\n",
    "\n",
    "# Define the model branches\n",
    "def lstm_branch(input_shape):\n",
    "    inputs = Input(shape=(input_shape[0],))\n",
    "    x = Embedding(input_dim=num_classes, output_dim=64)(inputs)\n",
    "    x = LSTM(128, return_sequences=False)(x)\n",
    "    return inputs, x\n",
    "\n",
    "def gru_branch(input_shape):\n",
    "    inputs = Input(shape=(input_shape[0],))\n",
    "    x = Embedding(input_dim=num_classes, output_dim=64)(inputs)\n",
    "    x = GRU(128, return_sequences=False)(x)\n",
    "    return inputs, x\n",
    "\n",
    "def transformer_branch(input_shape):\n",
    "    inputs = Input(shape=(input_shape[0],))\n",
    "    x = Embedding(input_dim=num_classes, output_dim=64)(inputs)\n",
    "    attn_output = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "    x = LayerNormalization()(x + attn_output)\n",
    "    x = GlobalMaxPooling1D()(x)  # Apply GlobalMaxPooling1D to convert 3D to 2D\n",
    "    return inputs, x\n",
    "\n",
    "def convnet_branch(input_shape):\n",
    "    inputs = Input(shape=(input_shape[0],))\n",
    "    x = Embedding(input_dim=num_classes, output_dim=64)(inputs)\n",
    "    x = Conv1D(128, kernel_size=3, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    return inputs, x\n",
    "\n",
    "# Define TFT branch\n",
    "def tft_branch(input_shape):\n",
    "    inputs = Input(shape=(input_shape[0],))\n",
    "    x = Embedding(input_dim=num_classes, output_dim=64)(inputs)\n",
    "    # Variable Selection Network\n",
    "    vsn = Dense(64, activation='relu')(x)\n",
    "    vsl = Dense(1, activation='sigmoid')(vsn)\n",
    "    x = x * vsl  # Apply variable selection\n",
    "    x = LayerNormalization()(x)\n",
    "    x = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    return inputs, x\n",
    "\n",
    "# Build the model\n",
    "def build_model(sequence_length):\n",
    "    # Define the branches for each input\n",
    "    lstm_event_inputs, lstm_event_output = lstm_branch((sequence_length,))\n",
    "    lstm_agent_inputs, lstm_agent_output = lstm_branch((sequence_length,))\n",
    "    lstm_context_inputs, lstm_context_output = lstm_branch((sequence_length,))\n",
    "    \n",
    "    gru_event_inputs, gru_event_output = gru_branch((sequence_length,))\n",
    "    gru_agent_inputs, gru_agent_output = gru_branch((sequence_length,))\n",
    "    gru_context_inputs, gru_context_output = gru_branch((sequence_length,))\n",
    "    \n",
    "    transformer_event_inputs, transformer_event_output = transformer_branch((sequence_length,))\n",
    "    transformer_agent_inputs, transformer_agent_output = transformer_branch((sequence_length,))\n",
    "    transformer_context_inputs, transformer_context_output = transformer_branch((sequence_length,))\n",
    "    \n",
    "    convnet_event_inputs, convnet_event_output = convnet_branch((sequence_length,))\n",
    "    convnet_agent_inputs, convnet_agent_output = convnet_branch((sequence_length,))\n",
    "    convnet_context_inputs, convnet_context_output = convnet_branch((sequence_length,))\n",
    "    \n",
    "    tft_event_inputs, tft_event_output = tft_branch((sequence_length,))\n",
    "    tft_agent_inputs, tft_agent_output = tft_branch((sequence_length,))\n",
    "    tft_context_inputs, tft_context_output = tft_branch((sequence_length,))\n",
    "    \n",
    "    # Concatenate outputs from all branches\n",
    "    concatenated = Concatenate()([\n",
    "        lstm_event_output, lstm_agent_output, lstm_context_output,\n",
    "        gru_event_output, gru_agent_output, gru_context_output,\n",
    "        transformer_event_output, transformer_agent_output, transformer_context_output,\n",
    "        convnet_event_output, convnet_agent_output, convnet_context_output,\n",
    "        tft_event_output, tft_agent_output, tft_context_output\n",
    "    ])\n",
    "    \n",
    "    shared_dense = Dense(128, activation='relu')(concatenated)\n",
    "    shared_dense = Dropout(0.5)(shared_dense)  # Dropout for regularization\n",
    "    \n",
    "    next_event_head = Dense(num_classes, activation='softmax', name='next_event')(shared_dense)\n",
    "    agent_head = Dense(num_agents, activation='softmax', name='agent')(shared_dense)\n",
    "    context_head = Dense(num_contexts, activation='softmax', name='context')(shared_dense)\n",
    "    anomaly_head = Dense(1, activation='sigmoid', name='anomaly')(shared_dense)\n",
    "    \n",
    "    model = Model(inputs=[\n",
    "        lstm_event_inputs, lstm_agent_inputs, lstm_context_inputs,\n",
    "        gru_event_inputs, gru_agent_inputs, gru_context_inputs,\n",
    "        transformer_event_inputs, transformer_agent_inputs, transformer_context_inputs,\n",
    "        convnet_event_inputs, convnet_agent_inputs, convnet_context_inputs,\n",
    "        tft_event_inputs, tft_agent_inputs, tft_context_inputs\n",
    "    ], outputs=[next_event_head, agent_head, context_head, anomaly_head])\n",
    "    \n",
    "    return model\n",
    "\n",
    "input_shape = (sequence_length,)\n",
    "model = build_model(sequence_length)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'next_event': 'categorical_crossentropy', \n",
    "                    'agent': 'categorical_crossentropy',\n",
    "                    'context': 'categorical_crossentropy', \n",
    "                    'anomaly': 'binary_crossentropy'},\n",
    "              loss_weights={'next_event': 1.0, 'agent': 0.5, 'context': 0.5, 'anomaly': 0.1},\n",
    "              metrics={'next_event': 'accuracy', \n",
    "                       'agent': 'accuracy',\n",
    "                       'context': 'accuracy',\n",
    "                       'anomaly': 'accuracy'})\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    [train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2],\n",
    "     train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2],\n",
    "     train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2],\n",
    "     train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2],\n",
    "     train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2]],\n",
    "    {'next_event': train_targets[0], 'agent': train_targets[1], 'context': train_targets[2], 'anomaly': train_targets[3]},\n",
    "    validation_data=(\n",
    "        [val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "         val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "         val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "         val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "         val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2]],\n",
    "        {'next_event': val_targets[0], 'agent': val_targets[1], 'context': val_targets[2], 'anomaly': val_targets[3]}\n",
    "    ),\n",
    "    epochs=50, batch_size=64\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv('training_results/RNN_Combine_model_GRU_TFT.csv', index=False)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = model.evaluate(\n",
    "    [test_sequences[:,:,0], test_sequences[:,:,1], test_sequences[:,:,2],\n",
    "     test_sequences[:,:,0], test_sequences[:,:,1], test_sequences[:,:,2],\n",
    "     test_sequences[:,:,0], test_sequences[:,:,1], test_sequences[:,:,2],\n",
    "     test_sequences[:,:,0], test_sequences[:,:,1], test_sequences[:,:,2],\n",
    "     test_sequences[:,:,0], test_sequences[:,:,1], test_sequences[:,:,2]],\n",
    "    {'next_event': test_targets[0], 'agent': test_targets[1], 'context': test_targets[2], 'anomaly': test_targets[3]}\n",
    ")\n",
    "print(f\"Test Loss and Accuracy: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer 'functional_1' expected 15 input(s). Received 9 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m sample_sequences \u001b[38;5;241m=\u001b[39m test_sequences[:num_samples]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Predict the next values\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m     \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m     \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Extract predictions\u001b[39;00m\n\u001b[0;32m     12\u001b[0m next_event_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:156\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_spec) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs):\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# Having a shape/dtype is the only commonality of the various\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# tensor-like objects that may be passed. The most common kind of\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# invalid type we are guarding for is a Layer instance (Functional API),\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# which does not have a `shape` attribute.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: Layer 'functional_1' expected 15 input(s). Received 9 instead."
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "sample_sequences = test_sequences[:num_samples]\n",
    "\n",
    "# Predict the next values\n",
    "predictions = model.predict(\n",
    "    [sample_sequences[:,:,0], sample_sequences[:,:,1], sample_sequences[:,:,2],\n",
    "     sample_sequences[:,:,0], sample_sequences[:,:,1], sample_sequences[:,:,2],\n",
    "     sample_sequences[:,:,0], sample_sequences[:,:,1], sample_sequences[:,:,2]]\n",
    ")\n",
    "\n",
    "# Extract predictions\n",
    "next_event_predictions = np.argmax(predictions[0], axis=-1)\n",
    "agent_predictions = np.argmax(predictions[1], axis=-1)\n",
    "context_predictions = np.argmax(predictions[2], axis=-1)\n",
    "anomaly_predictions = (predictions[3] > 0.5).astype(int)\n",
    "\n",
    "# Decode predictions\n",
    "def decode_predictions(predictions, id_to_label):\n",
    "    return [id_to_label[idx] for idx in predictions]\n",
    "\n",
    "decoded_next_event_predictions = decode_predictions(next_event_predictions, event_type_mapping)\n",
    "decoded_agent_predictions = decode_predictions(agent_predictions, agent_id_mapping)\n",
    "decoded_context_predictions = decode_predictions(context_predictions, context_mapping)\n",
    "\n",
    "# Decode input sequences\n",
    "def decode_sequences(sequences, event_mapping, agent_mapping, context_mapping):\n",
    "    decoded_sequences = []\n",
    "    for seq in sequences:\n",
    "        decoded_seq = []\n",
    "        for step in seq:\n",
    "            decoded_step = [\n",
    "                event_mapping[step[0]],\n",
    "                agent_mapping[step[1]],\n",
    "                context_mapping[step[2]]\n",
    "            ]\n",
    "            decoded_seq.append(decoded_step)\n",
    "        decoded_sequences.append(decoded_seq)\n",
    "    return np.array(decoded_sequences)\n",
    "\n",
    "decoded_sample_sequences = decode_sequences(sample_sequences, event_type_mapping, agent_id_mapping, context_mapping)\n",
    "\n",
    "# Print decoded input sequences and predictions\n",
    "for i in range(num_samples):\n",
    "    print(f\"Input sequence (event_id, agent_id, context):\\n{decoded_sample_sequences[i]}\")\n",
    "    print(f\"Predicted next event_id: {decoded_next_event_predictions[i]}\")\n",
    "    print(f\"Predicted next agent_id: {decoded_agent_predictions[i]}\")\n",
    "    print(f\"Predicted next context: {decoded_context_predictions[i]}\")\n",
    "    print(f\"Predicted anomaly: {anomaly_predictions[i]}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start the game!\n",
      "You'll provide the context for each step. The model will predict the event and agent.\n",
      "We'll play for 5 steps.\n",
      "\n",
      "Step 1:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_user_input(prompt, valid_options):\n",
    "    while True:\n",
    "        user_input = input(prompt).strip()\n",
    "        if user_input in valid_options:\n",
    "            return user_input\n",
    "        print(f\"Invalid input. Please choose from: {', '.join(valid_options)}\")\n",
    "\n",
    "def play_game(model, event_type_mapping, agent_id_mapping, context_mapping, sequence_length=10):\n",
    "    sequence = []\n",
    "    \n",
    "    print(\"Let's start the game!\")\n",
    "    print(f\"You'll provide the context for each step. The model will predict the event and agent.\")\n",
    "    print(f\"We'll play for {sequence_length} steps.\")\n",
    "    \n",
    "    for step in range(sequence_length):\n",
    "        print(f\"\\nStep {step + 1}:\")\n",
    "        \n",
    "        # Get context input from user\n",
    "        context_options = list(context_mapping)\n",
    "        context = get_user_input(\"Enter the context: \", context_options)\n",
    "        context_id = np.where(context_mapping == context)[0][0]\n",
    "        \n",
    "        # If we don't have enough history, use placeholder values\n",
    "        if len(sequence) < 3:\n",
    "            event_id = 0\n",
    "            agent_id = 0\n",
    "        else:\n",
    "            # Prepare input for model\n",
    "            model_input = np.array(sequence[-3:])\n",
    "            model_input = np.expand_dims(model_input, axis=0)\n",
    "            \n",
    "            # Make predictions\n",
    "            predictions = model.predict([model_input[:,:,0], model_input[:,:,1], model_input[:,:,2],\n",
    "                                         model_input[:,:,0], model_input[:,:,1], model_input[:,:,2],\n",
    "                                         model_input[:,:,0], model_input[:,:,1], model_input[:,:,2]])\n",
    "            \n",
    "            # Extract predictions\n",
    "            event_id = np.argmax(predictions[0][0])\n",
    "            agent_id = np.argmax(predictions[1][0])\n",
    "        \n",
    "        # Decode predictions\n",
    "        predicted_event = event_type_mapping[event_id]\n",
    "        predicted_agent = agent_id_mapping[agent_id]\n",
    "        \n",
    "        print(f\"Model predicts:\")\n",
    "        print(f\"Event: {predicted_event}\")\n",
    "        print(f\"Agent: {predicted_agent}\")\n",
    "        \n",
    "        # Add to sequence\n",
    "        sequence.append([event_id, agent_id, context_id])\n",
    "    \n",
    "    print(\"\\nGame over! Thanks for playing.\")\n",
    "\n",
    "# Start the game\n",
    "play_game(model, event_type_mapping, agent_id_mapping, context_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
