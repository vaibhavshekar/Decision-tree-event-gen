{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - agent_accuracy: 0.4091 - anomaly_accuracy: 0.4957 - context_accuracy: 0.0590 - loss: 2.6515 - next_event_accuracy: 0.6663 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.5000 - val_context_accuracy: 0.0878 - val_loss: 2.5696 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 251ms/step - agent_accuracy: 0.4054 - anomaly_accuracy: 0.5372 - context_accuracy: 0.0794 - loss: 2.5660 - next_event_accuracy: 0.8014 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.5068 - val_context_accuracy: 0.0878 - val_loss: 2.5696 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 283ms/step - agent_accuracy: 0.4082 - anomaly_accuracy: 0.5091 - context_accuracy: 0.0803 - loss: 2.5738 - next_event_accuracy: 0.7898 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.5068 - val_context_accuracy: 0.0878 - val_loss: 2.5695 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 334ms/step - agent_accuracy: 0.4086 - anomaly_accuracy: 0.5181 - context_accuracy: 0.0783 - loss: 2.5669 - next_event_accuracy: 0.8020 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.5000 - val_context_accuracy: 0.0878 - val_loss: 2.5695 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 261ms/step - agent_accuracy: 0.4173 - anomaly_accuracy: 0.5016 - context_accuracy: 0.0864 - loss: 2.5729 - next_event_accuracy: 0.7914 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.5000 - val_context_accuracy: 0.0878 - val_loss: 2.5694 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - agent_accuracy: 0.4029 - anomaly_accuracy: 0.5190 - context_accuracy: 0.0845 - loss: 2.5595 - next_event_accuracy: 0.8107 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.5135 - val_context_accuracy: 0.0878 - val_loss: 2.5694 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 243ms/step - agent_accuracy: 0.3907 - anomaly_accuracy: 0.5065 - context_accuracy: 0.0785 - loss: 2.5738 - next_event_accuracy: 0.7936 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5693 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 203ms/step - agent_accuracy: 0.3719 - anomaly_accuracy: 0.5001 - context_accuracy: 0.0859 - loss: 2.5686 - next_event_accuracy: 0.7997 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.0878 - val_loss: 2.5693 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - agent_accuracy: 0.3871 - anomaly_accuracy: 0.5495 - context_accuracy: 0.0729 - loss: 2.5808 - next_event_accuracy: 0.7831 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.0878 - val_loss: 2.5692 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - agent_accuracy: 0.3983 - anomaly_accuracy: 0.5288 - context_accuracy: 0.0905 - loss: 2.5673 - next_event_accuracy: 0.7983 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.4730 - val_context_accuracy: 0.0878 - val_loss: 2.5692 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 229ms/step - agent_accuracy: 0.3755 - anomaly_accuracy: 0.5496 - context_accuracy: 0.0721 - loss: 2.5910 - next_event_accuracy: 0.7689 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5691 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 259ms/step - agent_accuracy: 0.3859 - anomaly_accuracy: 0.5526 - context_accuracy: 0.0955 - loss: 2.5732 - next_event_accuracy: 0.7903 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.0878 - val_loss: 2.5691 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 230ms/step - agent_accuracy: 0.4374 - anomaly_accuracy: 0.5359 - context_accuracy: 0.0854 - loss: 2.5570 - next_event_accuracy: 0.8114 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.5000 - val_context_accuracy: 0.0878 - val_loss: 2.5691 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 227ms/step - agent_accuracy: 0.4056 - anomaly_accuracy: 0.5238 - context_accuracy: 0.0904 - loss: 2.5552 - next_event_accuracy: 0.8154 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.0878 - val_loss: 2.5690 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 211ms/step - agent_accuracy: 0.4095 - anomaly_accuracy: 0.5364 - context_accuracy: 0.0920 - loss: 2.5691 - next_event_accuracy: 0.7931 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.0878 - val_loss: 2.5690 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 203ms/step - agent_accuracy: 0.4152 - anomaly_accuracy: 0.5350 - context_accuracy: 0.0900 - loss: 2.5735 - next_event_accuracy: 0.7867 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.0878 - val_loss: 2.5690 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 235ms/step - agent_accuracy: 0.3904 - anomaly_accuracy: 0.5559 - context_accuracy: 0.0869 - loss: 2.5657 - next_event_accuracy: 0.8015 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.0878 - val_loss: 2.5689 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - agent_accuracy: 0.4079 - anomaly_accuracy: 0.5340 - context_accuracy: 0.0904 - loss: 2.5679 - next_event_accuracy: 0.7978 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.5068 - val_context_accuracy: 0.0878 - val_loss: 2.5689 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 228ms/step - agent_accuracy: 0.3994 - anomaly_accuracy: 0.5245 - context_accuracy: 0.0870 - loss: 2.5687 - next_event_accuracy: 0.7949 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.5000 - val_context_accuracy: 0.0878 - val_loss: 2.5688 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - agent_accuracy: 0.4022 - anomaly_accuracy: 0.5457 - context_accuracy: 0.0799 - loss: 2.5666 - next_event_accuracy: 0.7996 - val_agent_accuracy: 0.4054 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5688 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - agent_accuracy: 0.3897 - anomaly_accuracy: 0.5509 - context_accuracy: 0.0783 - loss: 2.5637 - next_event_accuracy: 0.8043 - val_agent_accuracy: 0.4189 - val_anomaly_accuracy: 0.4797 - val_context_accuracy: 0.0878 - val_loss: 2.5688 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - agent_accuracy: 0.4268 - anomaly_accuracy: 0.5451 - context_accuracy: 0.0857 - loss: 2.5582 - next_event_accuracy: 0.8102 - val_agent_accuracy: 0.4189 - val_anomaly_accuracy: 0.4797 - val_context_accuracy: 0.0878 - val_loss: 2.5688 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - agent_accuracy: 0.4136 - anomaly_accuracy: 0.5616 - context_accuracy: 0.0826 - loss: 2.5741 - next_event_accuracy: 0.7911 - val_agent_accuracy: 0.4189 - val_anomaly_accuracy: 0.5000 - val_context_accuracy: 0.0878 - val_loss: 2.5687 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - agent_accuracy: 0.4300 - anomaly_accuracy: 0.5267 - context_accuracy: 0.0754 - loss: 2.5652 - next_event_accuracy: 0.8012 - val_agent_accuracy: 0.4257 - val_anomaly_accuracy: 0.4797 - val_context_accuracy: 0.0878 - val_loss: 2.5687 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - agent_accuracy: 0.4044 - anomaly_accuracy: 0.5495 - context_accuracy: 0.0801 - loss: 2.5666 - next_event_accuracy: 0.8007 - val_agent_accuracy: 0.4122 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.0878 - val_loss: 2.5687 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - agent_accuracy: 0.4285 - anomaly_accuracy: 0.5761 - context_accuracy: 0.0782 - loss: 2.5656 - next_event_accuracy: 0.8000 - val_agent_accuracy: 0.4122 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.0878 - val_loss: 2.5686 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - agent_accuracy: 0.4193 - anomaly_accuracy: 0.5618 - context_accuracy: 0.0915 - loss: 2.5602 - next_event_accuracy: 0.8079 - val_agent_accuracy: 0.4054 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5686 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - agent_accuracy: 0.4059 - anomaly_accuracy: 0.5611 - context_accuracy: 0.0882 - loss: 2.5747 - next_event_accuracy: 0.7876 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.0878 - val_loss: 2.5686 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - agent_accuracy: 0.4225 - anomaly_accuracy: 0.5622 - context_accuracy: 0.0832 - loss: 2.5715 - next_event_accuracy: 0.7925 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5686 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - agent_accuracy: 0.3991 - anomaly_accuracy: 0.5162 - context_accuracy: 0.0894 - loss: 2.5686 - next_event_accuracy: 0.7959 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4797 - val_context_accuracy: 0.0878 - val_loss: 2.5685 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - agent_accuracy: 0.3894 - anomaly_accuracy: 0.5647 - context_accuracy: 0.0647 - loss: 2.5856 - next_event_accuracy: 0.7757 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4730 - val_context_accuracy: 0.0878 - val_loss: 2.5685 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - agent_accuracy: 0.4083 - anomaly_accuracy: 0.5396 - context_accuracy: 0.0717 - loss: 2.5743 - next_event_accuracy: 0.7899 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4730 - val_context_accuracy: 0.0878 - val_loss: 2.5685 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - agent_accuracy: 0.4152 - anomaly_accuracy: 0.5679 - context_accuracy: 0.0924 - loss: 2.5657 - next_event_accuracy: 0.7983 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4797 - val_context_accuracy: 0.0878 - val_loss: 2.5685 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - agent_accuracy: 0.3760 - anomaly_accuracy: 0.5338 - context_accuracy: 0.0832 - loss: 2.5720 - next_event_accuracy: 0.7945 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4797 - val_context_accuracy: 0.0878 - val_loss: 2.5685 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - agent_accuracy: 0.3844 - anomaly_accuracy: 0.5270 - context_accuracy: 0.0854 - loss: 2.5574 - next_event_accuracy: 0.8131 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4730 - val_context_accuracy: 0.0878 - val_loss: 2.5684 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - agent_accuracy: 0.3955 - anomaly_accuracy: 0.5357 - context_accuracy: 0.0679 - loss: 2.5587 - next_event_accuracy: 0.8131 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4730 - val_context_accuracy: 0.0878 - val_loss: 2.5684 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 37/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - agent_accuracy: 0.3870 - anomaly_accuracy: 0.5698 - context_accuracy: 0.0702 - loss: 2.5641 - next_event_accuracy: 0.8056 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5684 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 38/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - agent_accuracy: 0.4054 - anomaly_accuracy: 0.5601 - context_accuracy: 0.0871 - loss: 2.5712 - next_event_accuracy: 0.7918 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5684 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 39/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - agent_accuracy: 0.4056 - anomaly_accuracy: 0.5561 - context_accuracy: 0.0890 - loss: 2.5708 - next_event_accuracy: 0.7920 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5684 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 40/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - agent_accuracy: 0.4039 - anomaly_accuracy: 0.5609 - context_accuracy: 0.0834 - loss: 2.5722 - next_event_accuracy: 0.7910 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.0878 - val_loss: 2.5684 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 41/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - agent_accuracy: 0.3958 - anomaly_accuracy: 0.5441 - context_accuracy: 0.0722 - loss: 2.5803 - next_event_accuracy: 0.7809 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5683 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 42/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - agent_accuracy: 0.4102 - anomaly_accuracy: 0.5538 - context_accuracy: 0.0706 - loss: 2.5662 - next_event_accuracy: 0.8011 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5683 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 43/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - agent_accuracy: 0.3985 - anomaly_accuracy: 0.5880 - context_accuracy: 0.0963 - loss: 2.5578 - next_event_accuracy: 0.8088 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.0878 - val_loss: 2.5683 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 44/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - agent_accuracy: 0.4177 - anomaly_accuracy: 0.5656 - context_accuracy: 0.0911 - loss: 2.5653 - next_event_accuracy: 0.7986 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5683 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 45/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - agent_accuracy: 0.3813 - anomaly_accuracy: 0.5518 - context_accuracy: 0.0865 - loss: 2.5629 - next_event_accuracy: 0.8051 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5683 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 46/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - agent_accuracy: 0.4330 - anomaly_accuracy: 0.5546 - context_accuracy: 0.0862 - loss: 2.5494 - next_event_accuracy: 0.8215 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5683 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 47/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - agent_accuracy: 0.4068 - anomaly_accuracy: 0.5405 - context_accuracy: 0.0819 - loss: 2.5671 - next_event_accuracy: 0.7996 - val_agent_accuracy: 0.3919 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.0878 - val_loss: 2.5683 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 48/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - agent_accuracy: 0.4072 - anomaly_accuracy: 0.5501 - context_accuracy: 0.0855 - loss: 2.5655 - next_event_accuracy: 0.8000 - val_agent_accuracy: 0.3986 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5682 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 49/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - agent_accuracy: 0.4229 - anomaly_accuracy: 0.5534 - context_accuracy: 0.0935 - loss: 2.5522 - next_event_accuracy: 0.8172 - val_agent_accuracy: 0.4122 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5682 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "Epoch 50/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - agent_accuracy: 0.4254 - anomaly_accuracy: 0.5422 - context_accuracy: 0.0776 - loss: 2.5615 - next_event_accuracy: 0.8068 - val_agent_accuracy: 0.4122 - val_anomaly_accuracy: 0.4865 - val_context_accuracy: 0.0878 - val_loss: 2.5682 - val_next_event_accuracy: 0.7973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Updated learning rate: 9.999999974752427e-07\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - agent_accuracy: 0.4371 - anomaly_accuracy: 0.5059 - context_accuracy: 0.1109 - loss: 2.5637 - next_event_accuracy: 0.8018\n",
      "Test Results - Loss: 2.566058874130249, Next Event Accuracy: 0.43624159693717957, Agent Accuracy: 0.5503355860710144, Context Accuracy: 0.10738255083560944, Anomaly Accuracy: 0.7986577153205872\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Conv1D, GlobalMaxPooling1D, MultiHeadAttention, LayerNormalization, Attention, SimpleRNN\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Data Preprocessing\n",
    "def preprocess_data(df):\n",
    "    event_type_mapping = df['event_type'].astype('category').cat.categories\n",
    "    agent_id_mapping = df['agent_id'].astype('category').cat.categories\n",
    "    context_mapping = df['context'].astype('category').cat.categories\n",
    "\n",
    "    df['event_type'] = df['event_type'].astype('category').cat.codes\n",
    "    df['agent_id'] = df['agent_id'].astype('category').cat.codes\n",
    "    df['context'] = df['context'].astype('category').cat.codes\n",
    "\n",
    "    return df, event_type_mapping, agent_id_mapping, context_mapping\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('1k_single_agent_minmax.csv')\n",
    "df, event_type_mapping, agent_id_mapping, context_mapping = preprocess_data(df)\n",
    "\n",
    "# Define constants\n",
    "num_classes = df['event_type'].nunique()\n",
    "num_agents = df['agent_id'].nunique()\n",
    "num_contexts = df['context'].nunique()\n",
    "sequence_length = 10  # Adjust based on your data\n",
    "num_features = df.shape[1]  # Number of features\n",
    "\n",
    "# Create sequences for training\n",
    "def create_sequences(df, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(df) - sequence_length):\n",
    "        seq = df.iloc[i:i+sequence_length].values\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "sequences = create_sequences(df, sequence_length)\n",
    "\n",
    "# Splitting the data\n",
    "train_size = int(0.7 * len(sequences))\n",
    "val_size = int(0.15 * len(sequences))\n",
    "train_sequences = sequences[:train_size]\n",
    "val_sequences = sequences[train_size:train_size+val_size]\n",
    "test_sequences = sequences[train_size+val_size:]\n",
    "\n",
    "# Extract targets\n",
    "def extract_targets(sequences):\n",
    "    next_event = to_categorical(sequences[:, -1, 0], num_classes=num_classes)\n",
    "    agent = to_categorical(sequences[:, -1, 1], num_classes=num_agents)\n",
    "    context = to_categorical(sequences[:, -1, 2], num_classes=num_contexts)\n",
    "    anomaly = np.random.randint(0, 2, size=(sequences.shape[0], 1))  # Placeholder for anomaly\n",
    "    return next_event, agent, context, anomaly\n",
    "\n",
    "train_targets = extract_targets(train_sequences)\n",
    "val_targets = extract_targets(val_sequences)\n",
    "test_targets = extract_targets(test_sequences)\n",
    "\n",
    "# Define the model branches\n",
    "def lstm_branch(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Embedding(input_dim=num_classes, output_dim=64)(inputs)\n",
    "    x = LSTM(128, return_sequences=True)(x)\n",
    "    x = Attention()([x, x])\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    return inputs, x\n",
    "\n",
    "def transformer_branch(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Embedding(input_dim=num_classes, output_dim=64)(inputs)\n",
    "    attn_output = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "    x = LayerNormalization()(x + attn_output)\n",
    "    x = GlobalMaxPooling1D()(x)  # Apply GlobalMaxPooling1D to convert 3D to 2D\n",
    "    return inputs, x\n",
    "\n",
    "def convnet_branch(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Embedding(input_dim=num_classes, output_dim=64)(inputs)\n",
    "    x = Conv1D(128, kernel_size=3, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    return inputs, x\n",
    "\n",
    "def memory_network_branch(input_shape, memory_size=50):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    embedded_inputs = Embedding(input_dim=num_classes, output_dim=64)(inputs)\n",
    "    \n",
    "    # External memory\n",
    "    memory = SimpleRNN(memory_size, return_sequences=True)(embedded_inputs)\n",
    "    attention = Attention()([memory, memory])\n",
    "    memory_output = GlobalMaxPooling1D()(attention)\n",
    "    \n",
    "    return inputs, memory_output\n",
    "\n",
    "# Build the model\n",
    "def build_model(sequence_length):\n",
    "    input_shape = (sequence_length,)\n",
    "\n",
    "    # Define the branches for each input\n",
    "    lstm_event_inputs, lstm_event_output = lstm_branch(input_shape)\n",
    "    lstm_agent_inputs, lstm_agent_output = lstm_branch(input_shape)\n",
    "    lstm_context_inputs, lstm_context_output = lstm_branch(input_shape)\n",
    "    \n",
    "    transformer_event_inputs, transformer_event_output = transformer_branch(input_shape)\n",
    "    transformer_agent_inputs, transformer_agent_output = transformer_branch(input_shape)\n",
    "    transformer_context_inputs, transformer_context_output = transformer_branch(input_shape)\n",
    "    \n",
    "    convnet_event_inputs, convnet_event_output = convnet_branch(input_shape)\n",
    "    convnet_agent_inputs, convnet_agent_output = convnet_branch(input_shape)\n",
    "    convnet_context_inputs, convnet_context_output = convnet_branch(input_shape)\n",
    "    \n",
    "    memory_event_inputs, memory_event_output = memory_network_branch(input_shape)\n",
    "    memory_agent_inputs, memory_agent_output = memory_network_branch(input_shape)\n",
    "    memory_context_inputs, memory_context_output = memory_network_branch(input_shape)\n",
    "    \n",
    "    # Concatenate outputs from all branches\n",
    "    concatenated = Concatenate()([\n",
    "        lstm_event_output, lstm_agent_output, lstm_context_output,\n",
    "        transformer_event_output, transformer_agent_output, transformer_context_output,\n",
    "        convnet_event_output, convnet_agent_output, convnet_context_output,\n",
    "        memory_event_output, memory_agent_output, memory_context_output\n",
    "    ])\n",
    "    \n",
    "    shared_dense = Dense(128, activation='relu')(concatenated)\n",
    "    \n",
    "    next_event_head = Dense(num_classes, activation='softmax', name='next_event')(shared_dense)\n",
    "    agent_head = Dense(num_agents, activation='softmax', name='agent')(shared_dense)\n",
    "    context_head = Dense(num_contexts, activation='softmax', name='context')(shared_dense)\n",
    "    anomaly_head = Dense(1, activation='sigmoid', name='anomaly')(shared_dense)\n",
    "    \n",
    "    model = Model(inputs=[\n",
    "        lstm_event_inputs, lstm_agent_inputs, lstm_context_inputs,\n",
    "        transformer_event_inputs, transformer_agent_inputs, transformer_context_inputs,\n",
    "        convnet_event_inputs, convnet_agent_inputs, convnet_context_inputs,\n",
    "        memory_event_inputs, memory_agent_inputs, memory_context_inputs\n",
    "    ], outputs=[next_event_head, agent_head, context_head, anomaly_head])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_model(sequence_length)\n",
    "\n",
    "# Define learnable uncertainty parameters\n",
    "sigma_next_event = tf.Variable(1.0, dtype=tf.float32, trainable=True)\n",
    "sigma_agent = tf.Variable(1.0, dtype=tf.float32, trainable=True)\n",
    "sigma_context = tf.Variable(1.0, dtype=tf.float32, trainable=True)\n",
    "sigma_anomaly = tf.Variable(1.0, dtype=tf.float32, trainable=True)\n",
    "\n",
    "# Define custom loss functions with uncertainty weighting\n",
    "def uncertainty_loss(y_true, y_pred, sigma):\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)) / (2 * sigma ** 2) + tf.math.log(sigma)\n",
    "\n",
    "# Define meta-learner model for learning rate adjustment\n",
    "meta_input = Input(shape=(1,))\n",
    "meta_output = Dense(1, activation='linear')(meta_input)\n",
    "meta_model = Model(meta_input, meta_output)\n",
    "meta_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Initial learning rate\n",
    "initial_lr = 1e-3\n",
    "model_optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n",
    "\n",
    "# Compile the base model with the custom losses\n",
    "model.compile(optimizer=model_optimizer,\n",
    "              loss={'next_event': lambda y_true, y_pred: uncertainty_loss(y_true, y_pred, sigma_next_event),\n",
    "                    'agent': lambda y_true, y_pred: uncertainty_loss(y_true, y_pred, sigma_agent),\n",
    "                    'context': lambda y_true, y_pred: uncertainty_loss(y_true, y_pred, sigma_context),\n",
    "                    'anomaly': lambda y_true, y_pred: tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_true, y_pred)) / (2 * sigma_anomaly ** 2) + tf.math.log(sigma_anomaly)},\n",
    "              metrics={'next_event': 'accuracy', \n",
    "                       'agent': 'accuracy',\n",
    "                       'context': 'accuracy',\n",
    "                       'anomaly': 'accuracy'})\n",
    "\n",
    "# Training the model with meta-learning\n",
    "for epoch in range(50):\n",
    "    print(f\"Epoch {epoch+1}/50\")\n",
    "    \n",
    "    # Train the base model\n",
    "    history = model.fit(\n",
    "        [train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2],\n",
    "         train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2],\n",
    "         train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2],\n",
    "         train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2]],\n",
    "        {'next_event': train_targets[0], 'agent': train_targets[1], 'context': train_targets[2], 'anomaly': train_targets[3]},\n",
    "        validation_data=(\n",
    "            [val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "             val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "             val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "             val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2]],\n",
    "            {'next_event': val_targets[0], 'agent': val_targets[1], 'context': val_targets[2], 'anomaly': val_targets[3]}\n",
    "        ),\n",
    "        epochs=1, batch_size=64\n",
    "    )\n",
    "    \n",
    "    # Meta-learning: Adjust learning rate based on validation loss\n",
    "    val_loss = history.history['val_loss'][0]\n",
    "    new_lr = meta_model.predict(np.array([[val_loss]]))\n",
    "    new_lr = np.clip(new_lr, 1e-6, 1e-2)  # Clipping to prevent too large or small learning rates\n",
    "    model.optimizer.learning_rate.assign(new_lr[0][0])\n",
    "    print(f\"Updated learning rate: {new_lr[0][0]}\")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv('training_results/RNN_Combine_model_MemNetwork.csv', index=False)\n",
    "# Evaluate the model\n",
    "eval_results = model.evaluate(\n",
    "    [test_sequences[:,:,0], test_sequences[:,:,1], test_sequences[:,:,2],\n",
    "     test_sequences[:,:,0], test_sequences[:,:,1], test_sequences[:,:,2],\n",
    "     test_sequences[:,:,0], test_sequences[:,:,1], test_sequences[:,:,2],\n",
    "     test_sequences[:,:,0], test_sequences[:,:,1], test_sequences[:,:,2]],\n",
    "    {'next_event': test_targets[0], 'agent': test_targets[1], 'context': test_targets[2], 'anomaly': test_targets[3]}\n",
    ")\n",
    "\n",
    "print(f\"Test Results - Loss: {eval_results[0]}, Next Event Accuracy: {eval_results[1]}, Agent Accuracy: {eval_results[2]}, Context Accuracy: {eval_results[3]}, Anomaly Accuracy: {eval_results[4]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer 'functional_1' expected 12 input(s). Received 9 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m sample_sequences \u001b[38;5;241m=\u001b[39m test_sequences[:num_samples]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Predict the next values\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m     \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m     \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Extract predictions\u001b[39;00m\n\u001b[0;32m     12\u001b[0m next_event_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:156\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_spec) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs):\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# Having a shape/dtype is the only commonality of the various\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# tensor-like objects that may be passed. The most common kind of\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# invalid type we are guarding for is a Layer instance (Functional API),\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# which does not have a `shape` attribute.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: Layer 'functional_1' expected 12 input(s). Received 9 instead."
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "sample_sequences = test_sequences[:num_samples]\n",
    "\n",
    "# Predict the next values\n",
    "predictions = model.predict(\n",
    "    [sample_sequences[:,:,0], sample_sequences[:,:,1], sample_sequences[:,:,2],\n",
    "     sample_sequences[:,:,0], sample_sequences[:,:,1], sample_sequences[:,:,2],\n",
    "     sample_sequences[:,:,0], sample_sequences[:,:,1], sample_sequences[:,:,2]]\n",
    ")\n",
    "\n",
    "# Extract predictions\n",
    "next_event_predictions = np.argmax(predictions[0], axis=-1)\n",
    "agent_predictions = np.argmax(predictions[1], axis=-1)\n",
    "context_predictions = np.argmax(predictions[2], axis=-1)\n",
    "anomaly_predictions = (predictions[3] > 0.5).astype(int)\n",
    "\n",
    "# Decode predictions\n",
    "def decode_predictions(predictions, id_to_label):\n",
    "    return [id_to_label[idx] for idx in predictions]\n",
    "\n",
    "decoded_next_event_predictions = decode_predictions(next_event_predictions, event_type_mapping)\n",
    "decoded_agent_predictions = decode_predictions(agent_predictions, agent_id_mapping)\n",
    "decoded_context_predictions = decode_predictions(context_predictions, context_mapping)\n",
    "\n",
    "# Decode input sequences\n",
    "def decode_sequences(sequences, event_mapping, agent_mapping, context_mapping):\n",
    "    decoded_sequences = []\n",
    "    for seq in sequences:\n",
    "        decoded_seq = []\n",
    "        for step in seq:\n",
    "            decoded_step = [\n",
    "                event_mapping[step[0]],\n",
    "                agent_mapping[step[1]],\n",
    "                context_mapping[step[2]]\n",
    "            ]\n",
    "            decoded_seq.append(decoded_step)\n",
    "        decoded_sequences.append(decoded_seq)\n",
    "    return np.array(decoded_sequences)\n",
    "\n",
    "decoded_sample_sequences = decode_sequences(sample_sequences, event_type_mapping, agent_id_mapping, context_mapping)\n",
    "\n",
    "# Print decoded input sequences and predictions\n",
    "for i in range(num_samples):\n",
    "    print(f\"Input sequence (event_id, agent_id, context):\\n{decoded_sample_sequences[i]}\")\n",
    "    print(f\"Predicted next event_id: {decoded_next_event_predictions[i]}\")\n",
    "    print(f\"Predicted next agent_id: {decoded_agent_predictions[i]}\")\n",
    "    print(f\"Predicted next context: {decoded_context_predictions[i]}\")\n",
    "    print(f\"Predicted anomaly: {anomaly_predictions[i]}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
