{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | conv_f... | dense_... | gru_units | learni... | lstm_u... | transf... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5287 - context_accuracy: 0.4556 - loss: 0.7663 - next_event_accuracy: 1.0000\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-0.7571  \u001b[39m | \u001b[39m144.1    \u001b[39m | \u001b[39m202.3    \u001b[39m | \u001b[39m64.02    \u001b[39m | \u001b[39m0.00303  \u001b[39m | \u001b[39m92.18    \u001b[39m | \u001b[39m2.554    \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.4630 - context_accuracy: 0.4732 - loss: 0.7582 - next_event_accuracy: 1.0000\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-0.759   \u001b[39m | \u001b[39m99.76    \u001b[39m | \u001b[39m130.3    \u001b[39m | \u001b[39m140.2    \u001b[39m | \u001b[39m0.005393 \u001b[39m | \u001b[39m144.5    \u001b[39m | \u001b[39m6.111    \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5744 - context_accuracy: 0.4450 - loss: 0.8025 - next_event_accuracy: 1.0000\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-0.8026  \u001b[39m | \u001b[39m103.3    \u001b[39m | \u001b[39m232.6    \u001b[39m | \u001b[39m69.26    \u001b[39m | \u001b[39m0.006708 \u001b[39m | \u001b[39m144.1    \u001b[39m | \u001b[39m5.352    \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.4661 - context_accuracy: 0.4576 - loss: 0.7977 - next_event_accuracy: 1.0000\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m-0.7839  \u001b[39m | \u001b[39m90.95    \u001b[39m | \u001b[39m102.0    \u001b[39m | \u001b[39m217.7    \u001b[39m | \u001b[39m0.009683 \u001b[39m | \u001b[39m124.2    \u001b[39m | \u001b[39m6.154    \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5530 - context_accuracy: 0.4558 - loss: 0.8030 - next_event_accuracy: 1.0000\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-0.7955  \u001b[39m | \u001b[39m232.3    \u001b[39m | \u001b[39m235.8    \u001b[39m | \u001b[39m80.33    \u001b[39m | \u001b[39m0.0004002\u001b[39m | \u001b[39m96.61    \u001b[39m | \u001b[39m7.269    \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5426 - context_accuracy: 0.4689 - loss: 0.7667 - next_event_accuracy: 1.0000\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-0.7617  \u001b[39m | \u001b[39m106.8    \u001b[39m | \u001b[39m124.2    \u001b[39m | \u001b[39m139.6    \u001b[39m | \u001b[39m0.00261  \u001b[39m | \u001b[39m145.4    \u001b[39m | \u001b[39m5.373    \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - agent_accuracy: 0.4220 - anomaly_accuracy: 0.4989 - context_accuracy: 0.1142 - loss: 2.5254 - next_event_accuracy: 0.8048\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-2.544   \u001b[39m | \u001b[39m144.2    \u001b[39m | \u001b[39m166.4    \u001b[39m | \u001b[39m71.55    \u001b[39m | \u001b[39m1e-05    \u001b[39m | \u001b[39m78.6     \u001b[39m | \u001b[39m3.752    \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5210 - context_accuracy: 0.4707 - loss: 0.7414 - next_event_accuracy: 1.0000\n",
      "| \u001b[35m8        \u001b[39m | \u001b[35m-0.7338  \u001b[39m | \u001b[35m144.7    \u001b[39m | \u001b[35m203.0    \u001b[39m | \u001b[35m64.68    \u001b[39m | \u001b[35m0.009987 \u001b[39m | \u001b[35m92.84    \u001b[39m | \u001b[35m3.876    \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - agent_accuracy: 0.3893 - anomaly_accuracy: 0.5579 - context_accuracy: 0.1498 - loss: 2.5187 - next_event_accuracy: 0.8048\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-2.535   \u001b[39m | \u001b[39m138.4    \u001b[39m | \u001b[39m239.2    \u001b[39m | \u001b[39m64.0     \u001b[39m | \u001b[39m1e-05    \u001b[39m | \u001b[39m102.2    \u001b[39m | \u001b[39m2.0      \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.4306 - context_accuracy: 0.4227 - loss: 0.7581 - next_event_accuracy: 1.0000\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-0.7547  \u001b[39m | \u001b[39m97.73    \u001b[39m | \u001b[39m116.6    \u001b[39m | \u001b[39m173.5    \u001b[39m | \u001b[39m0.006588 \u001b[39m | \u001b[39m136.0    \u001b[39m | \u001b[39m5.943    \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - agent_accuracy: 0.3755 - anomaly_accuracy: 0.5310 - context_accuracy: 0.0796 - loss: 2.4911 - next_event_accuracy: 0.8048\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-2.506   \u001b[39m | \u001b[39m93.66    \u001b[39m | \u001b[39m118.3    \u001b[39m | \u001b[39m161.9    \u001b[39m | \u001b[39m1e-05    \u001b[39m | \u001b[39m168.6    \u001b[39m | \u001b[39m4.093    \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.4953 - context_accuracy: 0.5141 - loss: 0.7523 - next_event_accuracy: 1.0000\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-0.7532  \u001b[39m | \u001b[39m105.0    \u001b[39m | \u001b[39m124.7    \u001b[39m | \u001b[39m152.7    \u001b[39m | \u001b[39m0.008829 \u001b[39m | \u001b[39m121.3    \u001b[39m | \u001b[39m7.046    \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5673 - context_accuracy: 0.4662 - loss: 0.7296 - next_event_accuracy: 1.0000\n",
      "| \u001b[35m13       \u001b[39m | \u001b[35m-0.7268  \u001b[39m | \u001b[35m99.53    \u001b[39m | \u001b[35m113.0    \u001b[39m | \u001b[35m188.3    \u001b[39m | \u001b[35m0.01     \u001b[39m | \u001b[35m112.0    \u001b[39m | \u001b[35m7.211    \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5409 - context_accuracy: 0.5079 - loss: 0.7459 - next_event_accuracy: 1.0000\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-0.7288  \u001b[39m | \u001b[39m118.5    \u001b[39m | \u001b[39m135.1    \u001b[39m | \u001b[39m182.7    \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m124.0    \u001b[39m | \u001b[39m5.262    \u001b[39m |\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5027 - context_accuracy: 0.4591 - loss: 0.7639 - next_event_accuracy: 1.0000\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-0.7571  \u001b[39m | \u001b[39m86.04    \u001b[39m | \u001b[39m140.9    \u001b[39m | \u001b[39m179.1    \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m117.4    \u001b[39m | \u001b[39m2.486    \u001b[39m |\n",
      "=================================================================================================\n",
      "Best Hyperparameters: {'target': -0.7268495559692383, 'params': {'conv_filters': 99.53497160731588, 'dense_units': 113.0191884316559, 'gru_units': 188.310661390341, 'learning_rate': 0.01, 'lstm_units': 112.04524742391085, 'transformer_heads': 7.210598615343657}}\n",
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 491ms/step - agent_accuracy: 0.4627 - anomaly_accuracy: 0.5201 - context_accuracy: 0.0872 - loss: 3.4254 - next_event_accuracy: 0.7312 - val_agent_accuracy: 0.9932 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.1892 - val_loss: 1.3577 - val_next_event_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 230ms/step - agent_accuracy: 0.9697 - anomaly_accuracy: 0.4650 - context_accuracy: 0.2465 - loss: 1.2302 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5135 - val_context_accuracy: 0.2973 - val_loss: 1.0256 - val_next_event_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 225ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.4731 - context_accuracy: 0.3297 - loss: 0.9436 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5676 - val_context_accuracy: 0.4527 - val_loss: 0.8758 - val_next_event_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5420 - context_accuracy: 0.4502 - loss: 0.8487 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.6486 - val_context_accuracy: 0.4257 - val_loss: 0.8088 - val_next_event_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 226ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5165 - context_accuracy: 0.4812 - loss: 0.7465 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.6149 - val_context_accuracy: 0.4595 - val_loss: 0.7584 - val_next_event_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5580 - context_accuracy: 0.4460 - loss: 0.7467 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.6284 - val_context_accuracy: 0.3784 - val_loss: 0.7820 - val_next_event_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5366 - context_accuracy: 0.4622 - loss: 0.7238 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5743 - val_context_accuracy: 0.4324 - val_loss: 0.7581 - val_next_event_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.4829 - context_accuracy: 0.4966 - loss: 0.6800 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5676 - val_context_accuracy: 0.4865 - val_loss: 0.7724 - val_next_event_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5775 - context_accuracy: 0.5360 - loss: 0.6711 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.4932 - val_context_accuracy: 0.4730 - val_loss: 0.7543 - val_next_event_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5875 - context_accuracy: 0.5834 - loss: 0.6230 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.6419 - val_context_accuracy: 0.4595 - val_loss: 0.8149 - val_next_event_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6159 - context_accuracy: 0.5489 - loss: 0.6361 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5878 - val_context_accuracy: 0.4595 - val_loss: 0.8216 - val_next_event_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5664 - context_accuracy: 0.5742 - loss: 0.6026 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.6149 - val_context_accuracy: 0.4324 - val_loss: 0.8244 - val_next_event_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5882 - context_accuracy: 0.6004 - loss: 0.6078 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5676 - val_context_accuracy: 0.4527 - val_loss: 0.8188 - val_next_event_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6199 - context_accuracy: 0.6182 - loss: 0.5481 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5473 - val_context_accuracy: 0.4392 - val_loss: 0.9049 - val_next_event_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6173 - context_accuracy: 0.6645 - loss: 0.5203 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5946 - val_context_accuracy: 0.4189 - val_loss: 0.9457 - val_next_event_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6624 - context_accuracy: 0.6483 - loss: 0.5152 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.6351 - val_context_accuracy: 0.4595 - val_loss: 1.0169 - val_next_event_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6266 - context_accuracy: 0.6837 - loss: 0.4866 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5338 - val_context_accuracy: 0.4527 - val_loss: 1.0393 - val_next_event_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6142 - context_accuracy: 0.7467 - loss: 0.4205 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5676 - val_context_accuracy: 0.4324 - val_loss: 1.1048 - val_next_event_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5976 - context_accuracy: 0.7920 - loss: 0.3855 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5676 - val_context_accuracy: 0.4392 - val_loss: 1.1020 - val_next_event_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6360 - context_accuracy: 0.7057 - loss: 0.4215 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5135 - val_context_accuracy: 0.4392 - val_loss: 1.1651 - val_next_event_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6127 - context_accuracy: 0.7587 - loss: 0.3928 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5878 - val_context_accuracy: 0.4797 - val_loss: 1.2313 - val_next_event_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6460 - context_accuracy: 0.7976 - loss: 0.3537 - next_event_accuracy: 1.0000 - val_agent_accuracy: 0.9932 - val_anomaly_accuracy: 0.5068 - val_context_accuracy: 0.4189 - val_loss: 1.2794 - val_next_event_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6658 - context_accuracy: 0.7985 - loss: 0.3337 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5676 - val_context_accuracy: 0.4459 - val_loss: 1.3317 - val_next_event_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6793 - context_accuracy: 0.8160 - loss: 0.3226 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5338 - val_context_accuracy: 0.4527 - val_loss: 1.3555 - val_next_event_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6730 - context_accuracy: 0.8024 - loss: 0.3116 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5338 - val_context_accuracy: 0.4257 - val_loss: 1.4218 - val_next_event_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6704 - context_accuracy: 0.8328 - loss: 0.2852 - next_event_accuracy: 1.0000 - val_agent_accuracy: 0.9932 - val_anomaly_accuracy: 0.5338 - val_context_accuracy: 0.4257 - val_loss: 1.4712 - val_next_event_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.6852 - context_accuracy: 0.8376 - loss: 0.2819 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.6216 - val_context_accuracy: 0.4527 - val_loss: 1.4479 - val_next_event_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.7146 - context_accuracy: 0.8582 - loss: 0.2471 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5203 - val_context_accuracy: 0.4459 - val_loss: 1.5941 - val_next_event_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.7293 - context_accuracy: 0.8533 - loss: 0.2550 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5608 - val_context_accuracy: 0.4324 - val_loss: 1.5851 - val_next_event_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.7545 - context_accuracy: 0.8641 - loss: 0.2139 - next_event_accuracy: 1.0000 - val_agent_accuracy: 0.9932 - val_anomaly_accuracy: 0.5541 - val_context_accuracy: 0.4527 - val_loss: 1.6018 - val_next_event_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.7657 - context_accuracy: 0.8732 - loss: 0.2111 - next_event_accuracy: 1.0000 - val_agent_accuracy: 0.9932 - val_anomaly_accuracy: 0.5541 - val_context_accuracy: 0.4459 - val_loss: 1.7533 - val_next_event_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.7589 - context_accuracy: 0.9041 - loss: 0.1813 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5135 - val_context_accuracy: 0.4392 - val_loss: 1.8031 - val_next_event_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.7577 - context_accuracy: 0.8708 - loss: 0.2149 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5338 - val_context_accuracy: 0.4595 - val_loss: 1.8700 - val_next_event_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8066 - context_accuracy: 0.9015 - loss: 0.1852 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5608 - val_context_accuracy: 0.4189 - val_loss: 1.8455 - val_next_event_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.7836 - context_accuracy: 0.8783 - loss: 0.2094 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5541 - val_context_accuracy: 0.4797 - val_loss: 1.7700 - val_next_event_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.7958 - context_accuracy: 0.8999 - loss: 0.1773 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5270 - val_context_accuracy: 0.4662 - val_loss: 1.7802 - val_next_event_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 226ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8283 - context_accuracy: 0.8914 - loss: 0.1889 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5270 - val_context_accuracy: 0.4459 - val_loss: 1.9438 - val_next_event_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 233ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8141 - context_accuracy: 0.8681 - loss: 0.2039 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5135 - val_context_accuracy: 0.4324 - val_loss: 1.7999 - val_next_event_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8304 - context_accuracy: 0.8947 - loss: 0.1755 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5000 - val_context_accuracy: 0.4459 - val_loss: 1.9422 - val_next_event_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 232ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8217 - context_accuracy: 0.8903 - loss: 0.1680 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5608 - val_context_accuracy: 0.4392 - val_loss: 1.9068 - val_next_event_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 229ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8508 - context_accuracy: 0.8947 - loss: 0.1544 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5270 - val_context_accuracy: 0.4527 - val_loss: 1.9755 - val_next_event_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8536 - context_accuracy: 0.8863 - loss: 0.1537 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5405 - val_context_accuracy: 0.4257 - val_loss: 1.9471 - val_next_event_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8838 - context_accuracy: 0.9037 - loss: 0.1405 - next_event_accuracy: 1.0000 - val_agent_accuracy: 0.9932 - val_anomaly_accuracy: 0.5473 - val_context_accuracy: 0.4459 - val_loss: 1.9187 - val_next_event_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8611 - context_accuracy: 0.9105 - loss: 0.1278 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5405 - val_context_accuracy: 0.4392 - val_loss: 1.9901 - val_next_event_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8744 - context_accuracy: 0.8955 - loss: 0.1416 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5135 - val_context_accuracy: 0.4662 - val_loss: 2.0274 - val_next_event_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8721 - context_accuracy: 0.9043 - loss: 0.1268 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5338 - val_context_accuracy: 0.4392 - val_loss: 2.1007 - val_next_event_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8791 - context_accuracy: 0.9031 - loss: 0.1333 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5405 - val_context_accuracy: 0.4527 - val_loss: 2.0825 - val_next_event_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8669 - context_accuracy: 0.8877 - loss: 0.1512 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5473 - val_context_accuracy: 0.4595 - val_loss: 2.0875 - val_next_event_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8892 - context_accuracy: 0.8995 - loss: 0.1400 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5405 - val_context_accuracy: 0.4662 - val_loss: 2.1191 - val_next_event_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.8987 - context_accuracy: 0.9096 - loss: 0.1195 - next_event_accuracy: 1.0000 - val_agent_accuracy: 1.0000 - val_anomaly_accuracy: 0.5473 - val_context_accuracy: 0.4662 - val_loss: 2.0782 - val_next_event_accuracy: 1.0000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - agent_accuracy: 1.0000 - anomaly_accuracy: 0.5097 - context_accuracy: 0.4041 - loss: 2.5848 - next_event_accuracy: 1.0000\n",
      "Test Loss and Accuracy: [2.38590407371521, 1.0, 0.4899328947067261, 0.3959731459617615, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Dense, Concatenate, Conv1D, GlobalMaxPooling1D, MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Data Preprocessing\n",
    "def preprocess_data(df):\n",
    "    event_type_mapping = df['event_type'].astype('category').cat.categories\n",
    "    agent_id_mapping = df['agent_id'].astype('category').cat.categories\n",
    "    context_mapping = df['context'].astype('category').cat.categories\n",
    "\n",
    "    df['event_type'] = df['event_type'].astype('category').cat.codes\n",
    "    df['agent_id'] = df['agent_id'].astype('category').cat.codes\n",
    "    df['context'] = df['context'].astype('category').cat.codes\n",
    "\n",
    "    return df, event_type_mapping, agent_id_mapping, context_mapping\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('1k_single_agent_minmax.csv')\n",
    "df, event_type_mapping, agent_id_mapping, context_mapping = preprocess_data(df)\n",
    "\n",
    "# Define constants\n",
    "num_classes = df['event_type'].nunique()\n",
    "num_agents = df['agent_id'].nunique()\n",
    "num_contexts = df['context'].nunique()\n",
    "sequence_length = 10  # Adjust based on your data\n",
    "\n",
    "# Create sequences for training\n",
    "def create_sequences(df, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(df) - sequence_length):\n",
    "        seq = df.iloc[i:i+sequence_length].values\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "sequences = create_sequences(df, sequence_length)\n",
    "\n",
    "# Splitting the data\n",
    "train_size = int(0.7 * len(sequences))\n",
    "val_size = int(0.15 * len(sequences))\n",
    "train_sequences = sequences[:train_size]\n",
    "val_sequences = sequences[train_size:train_size+val_size]\n",
    "test_sequences = sequences[train_size+val_size:]\n",
    "\n",
    "# Extract targets\n",
    "def extract_targets(sequences):\n",
    "    next_event = to_categorical(sequences[:, -1, 0], num_classes=num_classes)\n",
    "    agent = to_categorical(sequences[:, -1, 1], num_classes=num_agents)\n",
    "    context = to_categorical(sequences[:, -1, 2], num_classes=num_contexts)\n",
    "    anomaly = np.random.randint(0, 2, size=(sequences.shape[0], 1))  # Placeholder for anomaly\n",
    "    return next_event, agent, context, anomaly\n",
    "\n",
    "train_targets = extract_targets(train_sequences)\n",
    "val_targets = extract_targets(val_sequences)\n",
    "test_targets = extract_targets(test_sequences)\n",
    "\n",
    "# Define model branches\n",
    "def lstm_branch(input_shape, units):\n",
    "    inputs = Input(shape=(input_shape[0],))\n",
    "    x = Embedding(input_dim=num_classes, output_dim=64)(inputs)\n",
    "    x = LSTM(units, return_sequences=False)(x)\n",
    "    return inputs, x\n",
    "\n",
    "def gru_branch(input_shape, units):\n",
    "    inputs = Input(shape=(input_shape[0],))\n",
    "    x = Embedding(input_dim=num_classes, output_dim=64)(inputs)\n",
    "    x = GRU(units, return_sequences=False)(x)\n",
    "    return inputs, x\n",
    "\n",
    "def transformer_branch(input_shape, num_heads):\n",
    "    inputs = Input(shape=(input_shape[0],))\n",
    "    x = Embedding(input_dim=num_classes, output_dim=64)(inputs)\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=64)(x, x)\n",
    "    x = LayerNormalization()(x + attn_output)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    return inputs, x\n",
    "\n",
    "def convnet_branch(input_shape, filters):\n",
    "    inputs = Input(shape=(input_shape[0],))\n",
    "    x = Embedding(input_dim=num_classes, output_dim=64)(inputs)\n",
    "    x = Conv1D(filters, kernel_size=3, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    return inputs, x\n",
    "\n",
    "# Build the model with hyperparameters\n",
    "def build_model(sequence_length, lstm_units, gru_units, transformer_heads, conv_filters, dense_units, learning_rate):\n",
    "    lstm_event_inputs, lstm_event_output = lstm_branch((sequence_length,), lstm_units)\n",
    "    lstm_agent_inputs, lstm_agent_output = lstm_branch((sequence_length,), lstm_units)\n",
    "    lstm_context_inputs, lstm_context_output = lstm_branch((sequence_length,), lstm_units)\n",
    "\n",
    "    gru_event_inputs, gru_event_output = gru_branch((sequence_length,), gru_units)\n",
    "    gru_agent_inputs, gru_agent_output = gru_branch((sequence_length,), gru_units)\n",
    "    gru_context_inputs, gru_context_output = gru_branch((sequence_length,), gru_units)\n",
    "\n",
    "    transformer_event_inputs, transformer_event_output = transformer_branch((sequence_length,), transformer_heads)\n",
    "    transformer_agent_inputs, transformer_agent_output = transformer_branch((sequence_length,), transformer_heads)\n",
    "    transformer_context_inputs, transformer_context_output = transformer_branch((sequence_length,), transformer_heads)\n",
    "\n",
    "    convnet_event_inputs, convnet_event_output = convnet_branch((sequence_length,), conv_filters)\n",
    "    convnet_agent_inputs, convnet_agent_output = convnet_branch((sequence_length,), conv_filters)\n",
    "    convnet_context_inputs, convnet_context_output = convnet_branch((sequence_length,), conv_filters)\n",
    "\n",
    "    # Concatenate outputs from all branches\n",
    "    concatenated = Concatenate()([\n",
    "        lstm_event_output, lstm_agent_output, lstm_context_output,\n",
    "        gru_event_output, gru_agent_output, gru_context_output,\n",
    "        transformer_event_output, transformer_agent_output, transformer_context_output,\n",
    "        convnet_event_output, convnet_agent_output, convnet_context_output\n",
    "    ])\n",
    "\n",
    "    shared_dense = Dense(dense_units, activation='relu')(concatenated)\n",
    "\n",
    "    next_event_head = Dense(num_classes, activation='softmax', name='next_event')(shared_dense)\n",
    "    agent_head = Dense(num_agents, activation='softmax', name='agent')(shared_dense)\n",
    "    context_head = Dense(num_contexts, activation='softmax', name='context')(shared_dense)\n",
    "    anomaly_head = Dense(1, activation='sigmoid', name='anomaly')(shared_dense)\n",
    "\n",
    "    model = Model(inputs=[\n",
    "        lstm_event_inputs, lstm_agent_inputs, lstm_context_inputs,\n",
    "        gru_event_inputs, gru_agent_inputs, gru_context_inputs,\n",
    "        transformer_event_inputs, transformer_agent_inputs, transformer_context_inputs,\n",
    "        convnet_event_inputs, convnet_agent_inputs, convnet_context_inputs\n",
    "    ], outputs=[next_event_head, agent_head, context_head, anomaly_head])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss={'next_event': 'categorical_crossentropy', \n",
    "                        'agent': 'categorical_crossentropy',\n",
    "                        'context': 'categorical_crossentropy', \n",
    "                        'anomaly': 'binary_crossentropy'},\n",
    "                  loss_weights={'next_event': 1.0, 'agent': 0.5, 'context': 0.5, 'anomaly': 0.1},\n",
    "                  metrics={'next_event': 'accuracy', \n",
    "                           'agent': 'accuracy',\n",
    "                           'context': 'accuracy',\n",
    "                           'anomaly': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# Define the objective function for Bayesian Optimization\n",
    "def objective_function(lstm_units, gru_units, transformer_heads, conv_filters, dense_units, learning_rate):\n",
    "    model = build_model(sequence_length, int(lstm_units), int(gru_units), int(transformer_heads), int(conv_filters), int(dense_units), learning_rate)\n",
    "    \n",
    "    history = model.fit(\n",
    "        [train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2],\n",
    "         train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2],\n",
    "         train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2],\n",
    "         train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2]],\n",
    "        {'next_event': train_targets[0], 'agent': train_targets[1], 'context': train_targets[2], 'anomaly': train_targets[3]},\n",
    "        validation_data=(\n",
    "            [val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "             val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "             val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "             val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2]],\n",
    "            {'next_event': val_targets[0], 'agent': val_targets[1], 'context': val_targets[2], 'anomaly': val_targets[3]}\n",
    "        ),\n",
    "        epochs=10, batch_size=64, verbose=0  # Set epochs to a lower value for faster tuning\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_results = model.evaluate(\n",
    "        [val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "         val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "         val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "         val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2]],\n",
    "        {'next_event': val_targets[0], 'agent': val_targets[1], 'context': val_targets[2], 'anomaly': val_targets[3]}\n",
    "    )\n",
    "    return -eval_results[0]  # Return negative validation loss for maximization\n",
    "\n",
    "# Define hyperparameter bounds\n",
    "pbounds = {\n",
    "    'lstm_units': (64, 256),\n",
    "    'gru_units': (64, 256),\n",
    "    'transformer_heads': (2, 8),\n",
    "    'conv_filters': (64, 256),\n",
    "    'dense_units': (64, 256),\n",
    "    'learning_rate': (1e-5, 1e-2)\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "optimizer.maximize(init_points=5, n_iter=10)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", optimizer.max)\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "best_params = optimizer.max['params']\n",
    "model = build_model(\n",
    "    sequence_length,\n",
    "    int(best_params['lstm_units']),\n",
    "    int(best_params['gru_units']),\n",
    "    int(best_params['transformer_heads']),\n",
    "    int(best_params['conv_filters']),\n",
    "    int(best_params['dense_units']),\n",
    "    best_params['learning_rate']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2],\n",
    "     train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2],\n",
    "     train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2],\n",
    "     train_sequences[:,:,0], train_sequences[:,:,1], train_sequences[:,:,2]],\n",
    "    {'next_event': train_targets[0], 'agent': train_targets[1], 'context': train_targets[2], 'anomaly': train_targets[3]},\n",
    "    validation_data=(\n",
    "        [val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "         val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "         val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2],\n",
    "         val_sequences[:,:,0], val_sequences[:,:,1], val_sequences[:,:,2]],\n",
    "        {'next_event': val_targets[0], 'agent': val_targets[1], 'context': val_targets[2], 'anomaly': val_targets[3]}\n",
    "    ),\n",
    "    epochs=50, batch_size=64\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv('training_results/RNN_Combine_model_GRU_Bayesian.csv', index=False)\n",
    "# Evaluate the final model\n",
    "eval_results = model.evaluate(\n",
    "    [test_sequences[:,:,0], test_sequences[:,:,1], test_sequences[:,:,2],\n",
    "     test_sequences[:,:,0], test_sequences[:,:,1], test_sequences[:,:,2],\n",
    "     test_sequences[:,:,0], test_sequences[:,:,1], test_sequences[:,:,2],\n",
    "     test_sequences[:,:,0], test_sequences[:,:,1], test_sequences[:,:,2]],\n",
    "    {'next_event': test_targets[0], 'agent': test_targets[1], 'context': test_targets[2], 'anomaly': test_targets[3]}\n",
    ")\n",
    "print(f\"Test Loss and Accuracy: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer 'functional_31' expected 12 input(s). Received 9 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m sample_sequences \u001b[38;5;241m=\u001b[39m test_sequences[:num_samples]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Predict the next values\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m     \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m     \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Extract predictions\u001b[39;00m\n\u001b[0;32m     12\u001b[0m next_event_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:156\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    154\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_spec) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs):\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# Having a shape/dtype is the only commonality of the various\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# tensor-like objects that may be passed. The most common kind of\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# invalid type we are guarding for is a Layer instance (Functional API),\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# which does not have a `shape` attribute.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: Layer 'functional_31' expected 12 input(s). Received 9 instead."
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "sample_sequences = test_sequences[:num_samples]\n",
    "\n",
    "# Predict the next values\n",
    "predictions = model.predict(\n",
    "    [sample_sequences[:,:,0], sample_sequences[:,:,1], sample_sequences[:,:,2],\n",
    "     sample_sequences[:,:,0], sample_sequences[:,:,1], sample_sequences[:,:,2],\n",
    "     sample_sequences[:,:,0], sample_sequences[:,:,1], sample_sequences[:,:,2]]\n",
    ")\n",
    "\n",
    "# Extract predictions\n",
    "next_event_predictions = np.argmax(predictions[0], axis=-1)\n",
    "agent_predictions = np.argmax(predictions[1], axis=-1)\n",
    "context_predictions = np.argmax(predictions[2], axis=-1)\n",
    "anomaly_predictions = (predictions[3] > 0.5).astype(int)\n",
    "\n",
    "# Decode predictions\n",
    "def decode_predictions(predictions, id_to_label):\n",
    "    return [id_to_label[idx] for idx in predictions]\n",
    "\n",
    "decoded_next_event_predictions = decode_predictions(next_event_predictions, event_type_mapping)\n",
    "decoded_agent_predictions = decode_predictions(agent_predictions, agent_id_mapping)\n",
    "decoded_context_predictions = decode_predictions(context_predictions, context_mapping)\n",
    "\n",
    "# Decode input sequences\n",
    "def decode_sequences(sequences, event_mapping, agent_mapping, context_mapping):\n",
    "    decoded_sequences = []\n",
    "    for seq in sequences:\n",
    "        decoded_seq = []\n",
    "        for step in seq:\n",
    "            decoded_step = [\n",
    "                event_mapping[step[0]],\n",
    "                agent_mapping[step[1]],\n",
    "                context_mapping[step[2]]\n",
    "            ]\n",
    "            decoded_seq.append(decoded_step)\n",
    "        decoded_sequences.append(decoded_seq)\n",
    "    return np.array(decoded_sequences)\n",
    "\n",
    "decoded_sample_sequences = decode_sequences(sample_sequences, event_type_mapping, agent_id_mapping, context_mapping)\n",
    "\n",
    "# Print decoded input sequences and predictions\n",
    "for i in range(num_samples):\n",
    "    print(f\"Input sequence (event_id, agent_id, context):\\n{decoded_sample_sequences[i]}\")\n",
    "    print(f\"Predicted next event_id: {decoded_next_event_predictions[i]}\")\n",
    "    print(f\"Predicted next agent_id: {decoded_agent_predictions[i]}\")\n",
    "    print(f\"Predicted next context: {decoded_context_predictions[i]}\")\n",
    "    print(f\"Predicted anomaly: {anomaly_predictions[i]}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start the game!\n",
      "You'll provide the context for each step. The model will predict the event and agent.\n",
      "We'll play for 5 steps.\n",
      "\n",
      "Step 1:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_user_input(prompt, valid_options):\n",
    "    while True:\n",
    "        user_input = input(prompt).strip()\n",
    "        if user_input in valid_options:\n",
    "            return user_input\n",
    "        print(f\"Invalid input. Please choose from: {', '.join(valid_options)}\")\n",
    "\n",
    "def play_game(model, event_type_mapping, agent_id_mapping, context_mapping, sequence_length=10):\n",
    "    sequence = []\n",
    "    \n",
    "    print(\"Let's start the game!\")\n",
    "    print(f\"You'll provide the context for each step. The model will predict the event and agent.\")\n",
    "    print(f\"We'll play for {sequence_length} steps.\")\n",
    "    \n",
    "    for step in range(sequence_length):\n",
    "        print(f\"\\nStep {step + 1}:\")\n",
    "        \n",
    "        # Get context input from user\n",
    "        context_options = list(context_mapping)\n",
    "        context = get_user_input(\"Enter the context: \", context_options)\n",
    "        context_id = np.where(context_mapping == context)[0][0]\n",
    "        \n",
    "        # If we don't have enough history, use placeholder values\n",
    "        if len(sequence) < 3:\n",
    "            event_id = 0\n",
    "            agent_id = 0\n",
    "        else:\n",
    "            # Prepare input for model\n",
    "            model_input = np.array(sequence[-3:])\n",
    "            model_input = np.expand_dims(model_input, axis=0)\n",
    "            \n",
    "            # Make predictions\n",
    "            predictions = model.predict([model_input[:,:,0], model_input[:,:,1], model_input[:,:,2],\n",
    "                                         model_input[:,:,0], model_input[:,:,1], model_input[:,:,2],\n",
    "                                         model_input[:,:,0], model_input[:,:,1], model_input[:,:,2]])\n",
    "            \n",
    "            # Extract predictions\n",
    "            event_id = np.argmax(predictions[0][0])\n",
    "            agent_id = np.argmax(predictions[1][0])\n",
    "        \n",
    "        # Decode predictions\n",
    "        predicted_event = event_type_mapping[event_id]\n",
    "        predicted_agent = agent_id_mapping[agent_id]\n",
    "        \n",
    "        print(f\"Model predicts:\")\n",
    "        print(f\"Event: {predicted_event}\")\n",
    "        print(f\"Agent: {predicted_agent}\")\n",
    "        \n",
    "        # Add to sequence\n",
    "        sequence.append([event_id, agent_id, context_id])\n",
    "    \n",
    "    print(\"\\nGame over! Thanks for playing.\")\n",
    "\n",
    "# Start the game\n",
    "play_game(model, event_type_mapping, agent_id_mapping, context_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
